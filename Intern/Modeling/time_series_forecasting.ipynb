{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nProblem Statement\\n\\nBuild a model which predicts sales \\nbased on the money spent on different category\\nfor online shopping mall\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Problem Statement\n",
    "\n",
    "Build a model which predicts sales \n",
    "based on the money spent on different category\n",
    "for online shopping mall\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from scipy.stats import norm, skew # for some statistics\n",
    "from scipy import stats #qqplot\n",
    "import statsmodels.api as sm # for decomposing the trends, seasonality etc.\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX # the big daddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "\n",
    "Column = IntEnum(\"Column\", \"DATE DEMAND CATEGORY CODE COLOR\")\n",
    "Dataset = IntEnum(\"Dataset\", \"ORIGIN ACCU_RATE ACCU_DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (3,4,14,18,20,22,23,24,26,27,28,29,32,33,35,44,49,53,54,55,56,74,76,77,79,80,81,82,83,86,87,89,93,94,95,98,102,109,110,111,112,116,119,120,124,125,126,127,128,129,130,131,132,133,137,138,139,140,142,144,145,146,150,151,153,155,157,159,160,161,162,163,164,166,170,172,173,174,176,177,178,179,180,181,182,183,184,187,188,189,190,192,194,198,202,204,205,206,208,209,210,211,212,213,214,215,216,217,221,222,225,227,228,229,230) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read original data file\n",
    "data = pd.read_csv('dali_data.csv')\n",
    "\n",
    "dataset = pd.DataFrame(\n",
    "    columns=list(name for name, __ in Column.__members__.items()))\n",
    "\n",
    "dataset[[Column.DATE.name, Column.CATEGORY.name, Column.DEMAND.name]] = data[\n",
    "    [\"date\", \"category\", \"quantity\"]]\n",
    "\n",
    "dataset[Column.DATE.name] = pd.to_datetime(dataset[Column.DATE.name])\n",
    "\n",
    "# separate item ID and item color\n",
    "dataset[Column.CODE.name] = pd.DataFrame(data['order_id'].str.split('-').tolist())[1]\n",
    "dataset[Column.COLOR.name] = pd.DataFrame(data['order_item_code'].str.split('-').tolist())[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null(dataset):\n",
    "    print('check any number of columns with NaN')\n",
    "    print(dataset.isnull().any().sum(), ' / ', len(dataset.columns), '\\n')\n",
    "\n",
    "    print('check any number of data points with NaN')\n",
    "    print(dataset.isnull().any(axis=1).sum(), ' / ', len(dataset), '\\n')\n",
    "\n",
    "    print('check where those nulls are')\n",
    "    print(dataset.isna().sum(), '\\n')\n",
    "    print('Null to Dataset Ratio in Dates: ', dataset.isnull().sum()[0] / dataset.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72659, 5)\n",
      "DATE        datetime64[ns]\n",
      "DEMAND               int64\n",
      "CATEGORY            object\n",
      "CODE                object\n",
      "COLOR               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check the cardinality\n",
    "print(dataset.shape)\n",
    "\n",
    "# check the data types\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check any number of columns with NaN\n",
      "1  /  5 \n",
      "\n",
      "check any number of data points with NaN\n",
      "96  /  72659 \n",
      "\n",
      "check where those nulls are\n",
      "DATE         0\n",
      "DEMAND       0\n",
      "CATEGORY    96\n",
      "CODE         0\n",
      "COLOR        0\n",
      "dtype: int64 \n",
      "\n",
      "Null to Dataset Ratio in Dates:  0.0\n"
     ]
    }
   ],
   "source": [
    "check_null(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-01-01 00:00:00'), Timestamp('2020-05-31 00:00:00'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the lowest and highest dates in the dataset\n",
    "dataset[Column.DATE.name].min(), dataset[Column.DATE.name].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify dataset\n",
    "dataset[Column.CATEGORY.name].replace({\n",
    "    \"원피스\": \"Dress\", \"블라우스\": \"Blouse\", \"스커트\": \"Skirt\", \"니트\": \"Knit\", \"티셔츠\": \"Tee\",\n",
    "    \"귀걸이\": \"Earring\", \"바지\": \"Pants\", \"잠옷/홈웨어\": \"Homewear\", \"셔츠\": \"Shirt\", \"목걸이\": \"Necklace\",\n",
    "    \"신발\": \"Shoes\", \"재킷\": \"Jacket\", \"숄/스카프/머플러\": \"Scarf\", \"코트\": \"Coat\", \"가디건\": \"Cardigan\",\n",
    "    \"투피스\": \"Two piece\", \"기타소품\": \"Accessory\", \"양말\": \"Socks\", \"보정속옷\": \"Underwear\",\n",
    "    \"기타상의\": \"Top\", \"기타여성잡화\": \"Accessory\", \"헤어엑세서리\": \"Accessory\", \"벨트\": \"Belts\",\n",
    "    \"가방\": \"Bag\", \"스타킹\": \"Stockings\", \"반지\": \"Ring\", \"팔찌/발찌\": \"Accessory\", \"브라\": \"Underwear\",\n",
    "    \"팬티\": \"Underwear\", \"점퍼\": \"Puffer jacket\", \"레깅스\": \"Leggings\", \"조끼\": \"Vest\", \"점프수트\": \"Jumpsuit\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[Column.CATEGORY.name].replace({\n",
    "    \"마스크\": np.nan, \"주얼리 세트\": np.nan, \"기타아우터\": np.nan, \"브로치\": np.nan, \"기타시계\": np.nan,\n",
    "    \"장갑\": np.nan, \"휴대폰케이스\": np.nan, \"디지털시계\": np.nan, \"시계 액세서리\": np.nan,\n",
    "    \"기타하의\": np.nan, \"기타용품\": np.nan, \"모자\": np.nan\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop na's\n",
    "dataset.dropna(axis=0, inplace=True) # remove all rows with na's\n",
    "dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check any number of columns with NaN\n",
      "0  /  5 \n",
      "\n",
      "check any number of data points with NaN\n",
      "0  /  72325 \n",
      "\n",
      "check where those nulls are\n",
      "DATE        0\n",
      "DEMAND      0\n",
      "CATEGORY    0\n",
      "CODE        0\n",
      "COLOR       0\n",
      "dtype: int64 \n",
      "\n",
      "Null to Dataset Ratio in Dates:  0.0\n"
     ]
    }
   ],
   "source": [
    "check_null(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_by_date(dataset, category):\n",
    "#     df_origin = dataset.groupby(\n",
    "#         [Column.CATEGORY.name, Column.CODE.name, Column.COLOR.name, Column.DATE.name]).sum().reset_index()\n",
    "    \n",
    "    df_origin = dataset.groupby(\n",
    "            [Column.CATEGORY.name, Column.DATE.name]).sum().reset_index()\n",
    "    \n",
    "    df_item = df_origin.loc[df_origin[Column.CATEGORY.name] == category].to_dict('records')\n",
    "    \n",
    "    df_new = pd.DataFrame(\n",
    "        columns=list(name for name, __ in Column.__members__.items()))\n",
    "    \n",
    "    min_date = str(dataset[Column.DATE.name].min()).split(' ')[0]\n",
    "    max_date = str(dataset[Column.DATE.name].max()).split(' ')[0]\n",
    "    \n",
    "    df_new[Column.DATE.name] = pd.date_range(min_date, max_date, freq='d')\n",
    "    df_new[Column.CATEGORY.name] = category\n",
    "    \n",
    "    # treat as 0 where there is no demand\n",
    "    df_new[Column.DEMAND.name].fillna(0, inplace=True)\n",
    "#     df_new[Column.CODE.name].fillna('-', inplace=True)\n",
    "#     df_new[Column.COLOR.name].fillna('-', inplace=True)\n",
    "    \n",
    "    for values in df_item:       \n",
    "        df_new[Column.DEMAND.name].mask(\n",
    "            df_new[Column.DATE.name] == values[Column.DATE.name], values[Column.DEMAND.name], inplace=True)\n",
    "#         df_new[Column.CODE.name].mask(\n",
    "#             df_new[Column.DATE.name] == values[Column.DATE.name], values[Column.CODE.name], inplace=True)\n",
    "#         df_new[Column.COLOR.name].mask(\n",
    "#             df_new[Column.DATE.name] == values[Column.DATE.name], values[Column.COLOR.name], inplace=True)\n",
    "        \n",
    "    return df_new.set_index(Column.DATE.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_3days(df_category):\n",
    "    # daily sales value for 3 days\n",
    "    df_category['3days'] = df_category['order_demand'].rolling(3).sum()\n",
    "    df_category['3days'] = df_category['3days'].fillna(0)\n",
    "    \n",
    "    # time series decomposition\n",
    "    stl = sm.tsa.STL(df_category['3days']).fit()\n",
    "    df_category['trend'] = list(stl.trend)\n",
    "    \n",
    "    check_null(df_category)\n",
    "    \n",
    "    rcParams['figure.figsize'] = 18, 8\n",
    "    df_category['3days'].plot(\n",
    "        title='3 Days ' + df_category.product_category[0] + ' Sales')\n",
    "    df_category['trend'].plot()\n",
    "    plt.show()\n",
    "\n",
    "    return df_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(df, window):\n",
    "    num = len(df) - window + 1\n",
    "\n",
    "    dict_data = {i+1: list(df.iloc[i:num+i, Column.DEMAND-1]) for i in range(window)} # column: day 1 ~ day window\n",
    "    df_accu_data = pd.DataFrame(\n",
    "        np.add.accumulate(list(dict_data.values())).T, columns=[i+1 for i in range(window)])\n",
    "    \n",
    "    dict_data[Column.CATEGORY.name] \\\n",
    "        = df_accu_data[Column.CATEGORY.name] = list(df.iloc[0:num, Column.CATEGORY])\n",
    "    \n",
    "    df_origin = pd.DataFrame(dict_data)\n",
    "    df_accu_rate = df_origin.copy(deep=True)\n",
    "\n",
    "    df_origin['RATE'] = rating(df_origin, window)\n",
    "    df_accu_rate['RATE'] = df_accu_data['RATE'] = rating(df_accu_data, window)\n",
    "    \n",
    "    return [df_origin, df_accu_rate, df_accu_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating(df, window):\n",
    "    lst_rate = [\n",
    "        (df[window][i] - df[1][i]) / abs(df[1][i])\n",
    "        if abs(df[1][i]) != 0 else df[window][i] - df[1][i] # if day 1's demand is 0\n",
    "        for i in range(len(df))\n",
    "    ]\n",
    "    \n",
    "    return lst_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(dataset, window, rate):\n",
    "    lst_category = sorted(list(dataset[Column.CATEGORY.name].unique()))\n",
    "    df_dict = {category: reconstruct_by_date(dataset, category) for category in lst_category}\n",
    "    \n",
    "    dict_labeled_dataset = {}\n",
    "     \n",
    "    for category in lst_category:\n",
    "        df_dict[category].reset_index(inplace=True)\n",
    "        lst_preprocess = data_preprocess(df_dict[category], window)\n",
    "\n",
    "        if category != lst_category[0]:\n",
    "            for i in range(len(Dataset)):\n",
    "                dict_labeled_dataset[i+1] = pd.concat(\n",
    "                    [dict_labeled_dataset[i+1], lst_preprocess[i]])\n",
    "\n",
    "        else:\n",
    "            # create dataframe for the very first category\n",
    "            dict_labeled_dataset[Dataset.ORIGIN] = lst_preprocess[Dataset.ORIGIN-1] # origin data + origin rate\n",
    "            dict_labeled_dataset[Dataset.ACCU_RATE] = lst_preprocess[Dataset.ACCU_RATE-1] # origin data + accumulated rate\n",
    "            dict_labeled_dataset[Dataset.ACCU_DATA] = lst_preprocess[Dataset.ACCU_DATA-1] # accumulated data + accumulated rate\n",
    "\n",
    "    print(\"window\")\n",
    "    print(window)\n",
    "    \n",
    "    dict_labeled_dataset, lst_label_count = labeling(dict_labeled_dataset, rate)\n",
    "    \n",
    "    return dict_labeled_dataset, lst_label_count # origin label count, accumulated label count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(dict_labeled_dataset, rate):\n",
    "    lst_label_count = []\n",
    "    \n",
    "    for i in range(len(Dataset)):\n",
    "        dict_labeled_dataset[i+1].reset_index(drop=True, inplace=True)\n",
    "        dict_labeled_dataset[i+1]['LABEL'] = np.where(\n",
    "            dict_labeled_dataset[i+1]['RATE'].apply(lambda rate: rate > rate), 1, 0)\n",
    "        \n",
    "        print(\"\\n rate description\")\n",
    "        print(dict_labeled_dataset[i+1]['RATE'].describe())\n",
    "\n",
    "        label = np.array(dict_labeled_dataset[i+1]['LABEL'])\n",
    "        label_count = np.where(label >= 1)[0].shape[0]\n",
    "        lst_label_count.append(label_count)\n",
    "\n",
    "        print(\"\\ncount above rate \" + str(rate))\n",
    "        print(label_count)\n",
    "    \n",
    "    return dict_labeled_dataset, lst_label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare(dataset):\n",
    "    dict_dfs = {i+1: {} for i in range(len(Dataset))}\n",
    "    dict_counts = deepcopy(dict_dfs)\n",
    "\n",
    "    for i in range(len(Dataset)):\n",
    "        dict_dfs[i+1] = {window: {} for window in range(min_window, max_window+1)}\n",
    "        dict_counts[i+1] = {window: [] for window in range(min_window, max_window+1)}\n",
    "\n",
    "    for window in range(min_window, max_window+1):\n",
    "        for rate in range(min_rate, max_rate+1):\n",
    "            dict_labeled_dataset, lst_label_count = data_process(dataset, window, rate)\n",
    "\n",
    "            dict_dfs[Dataset.ORIGIN][window][rate] = dict_labeled_dataset[Dataset.ORIGIN]\n",
    "            dict_dfs[Dataset.ACCU_RATE][window][rate] = dict_labeled_dataset[Dataset.ACCU_RATE]\n",
    "            dict_dfs[Dataset.ACCU_DATA][window][rate] = dict_labeled_dataset[Dataset.ACCU_DATA]\n",
    "\n",
    "            dict_counts[Dataset.ORIGIN][window].append(lst_label_count[Dataset.ORIGIN-1])\n",
    "            dict_counts[Dataset.ACCU_RATE][window].append(lst_label_count[Dataset.ACCU_RATE-1])\n",
    "            dict_counts[Dataset.ACCU_DATA][window].append(lst_label_count[Dataset.ACCU_DATA-1])\n",
    "            \n",
    "    return dict_dfs, dict_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graph(dict_counts):\n",
    "    for i in range(len(Dataset)-1):\n",
    "        df_count = pd.DataFrame(dict_counts[i]).T\n",
    "        df_count.rename(columns=dict(zip(\n",
    "            list(i for i in range(max_rate-min_rate+1)), list(rate for rate in range(\n",
    "                min_rate, max_rate+1)))), inplace=True)\n",
    "        \n",
    "        plot_title = {ORIGIN: 'Original ', ACCU_RATE: 'Accumulated Rate ', ACCU_DATA: ' Accumulated Data '}\n",
    "        \n",
    "        ax = df_count.plot(title=plot_title[i] + 'Label Count', figsize=(18, 9))\n",
    "        ax.set_xlabel('Window')\n",
    "        ax.set_ylabel('Counts')\n",
    "        \n",
    "        print(df_count)\n",
    "        print(df_count.describe())\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window\n",
      "3\n",
      "\n",
      " rate description\n",
      "count    14420.000000\n",
      "mean         0.254921\n",
      "std          1.831077\n",
      "min         -1.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max        148.000000\n",
      "Name: RATE, dtype: float64\n",
      "\n",
      "count above rate 3\n",
      "0\n",
      "\n",
      " rate description\n",
      "count    14420.000000\n",
      "mean         1.318778\n",
      "std          2.998575\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.500000\n",
      "75%          2.000000\n",
      "max        242.000000\n",
      "Name: RATE, dtype: float64\n",
      "\n",
      "count above rate 3\n",
      "0\n",
      "\n",
      " rate description\n",
      "count    14420.000000\n",
      "mean         1.318778\n",
      "std          2.998575\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.500000\n",
      "75%          2.000000\n",
      "max        242.000000\n",
      "Name: RATE, dtype: float64\n",
      "\n",
      "count above rate 3\n",
      "0\n",
      "window\n",
      "3\n",
      "\n",
      " rate description\n",
      "count    14420.000000\n",
      "mean         0.254921\n",
      "std          1.831077\n",
      "min         -1.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max        148.000000\n",
      "Name: RATE, dtype: float64\n",
      "\n",
      "count above rate 4\n",
      "0\n",
      "\n",
      " rate description\n",
      "count    14420.000000\n",
      "mean         1.318778\n",
      "std          2.998575\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.500000\n",
      "75%          2.000000\n",
      "max        242.000000\n",
      "Name: RATE, dtype: float64\n",
      "\n",
      "count above rate 4\n",
      "0\n",
      "\n",
      " rate description\n",
      "count    14420.000000\n",
      "mean         1.318778\n",
      "std          2.998575\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.500000\n",
      "75%          2.000000\n",
      "max        242.000000\n",
      "Name: RATE, dtype: float64\n",
      "\n",
      "count above rate 4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "min_window = 3\n",
    "max_window = 3\n",
    "\n",
    "min_rate = 3\n",
    "max_rate = 4\n",
    "\n",
    "dict_dfs, dict_counts = data_prepare(dataset)\n",
    "show_graph(dict_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
